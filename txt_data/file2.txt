 I SANJIV.T.S IT-B DBMS CAT. - 3:- 200801075 8)b). Deadlock Handling Consider the following two transactions and history, with item X and transaction Ti at site and item Y and transaction T2 at site 2: II: write(x) T2 write/x) write (r) write(Y) x-lock on x write (x) X- lock on Y write (Y) wait for X lock on X. wait for x - lock on & Result: deadlock which cannot be detected locally at either site Deadlock Detection:- In the centralized deadlock- detection approach, a global wait for graph is constructed and maintained in a single site; the deadlock- detection coordinator : Real graph real, but unknown, state system of the constructed graph Approximation generated by the controller during the execution of its algorithm 2 . The global wait-for graph can be constructed when: a new edge is inserted in or removed from one of the local wait - for graphs. A number of changes have occurred in a local wail-for gaph. The coordinates needs to invoke cycle - detection. . If the coordinate finds a cycle, it selects a rictim and notifies all sites The sites roll back the victim transaction. Local and Global Wait-for Graphs: TI T2 2 T4 LOCAL T3 T5 T3 site S, site S2 11 T2 T4 Global. T5 T3 3 Example wait -for Graph for False cycles:- Initial state: II TV T3 T2 SI 52 T1 T2 T3 coordinator False Cycles:- . Suppose that starting from the state shown in figure T2 releases resources at S1 resulting in a message remove II T2 masage from the Transaction Manager at site S, to the cooriderator 4 2. And then T2 requests a resource held by T3 at the site S2 resulting in a message insert T2 2T3 from S2 to the coordinator 3. Suppose further that the insert message reaches before the delete message. O this can happen due to network delays The coordinator would then find a false 4. cycle II T2 T3 TI 5. The false cycle above neer existed in reality 6. False cycles cannot occur if two-phase locking is used. Distributed Deadlocks :- Unnecessary rollbacks may result when deadlock has indeed occurred and a victim has been picked, and meanwhile one of the transactions was aborted for reasons unrelated to the deadlock 5 . Due to false cycles in the global wait-for graph, however, litelihood of false cycles is low In the distributed deadlock- - detection approach, sites exchange wait for information and check for deadlocks 0 Expensive and not used in practice. 7)a) Torrent protoce enables decentralization of its resources by making use of peer to per network A small torrent file is created to represent a file or a folder to be shared users can download the required files using a unique magnet link associated to each file on torrent In order to learn the Internet location of the peer which may be sharing pieces, the client connects to the trachers named in the torrent file, achieve a similar hosh result through the use of distributed tables The technology to ensure fault bolerance is fault- Tonerat services using deplicated State Machines. 6 0 key requirement male a service fault tolerant Eg torrent, lock manager, etc. . state machines are a powerful approach to creating such services A state machine O Has a stored state and receive inputs , Makes state transitions on each input and may output some results . Transitions and outputs must be determinities > A replicated state machine is a state mached that is replicated on multiple modes All replica must get exactly the same inputs Replicated log state machine processor only committed inputs Even of some nodes fail, state and output can be obtained from other nodes 7 client consensus I 3 consenses £ 3 module Module y 7 y 73 2 3 2 log xc2 (1262/163) yeu yez IE2/2E2 I xe3 y 41 yer leader follower uses of Replicated State Machines . Inputs can specify operations with parameters, But operations must be deterministic Result of operation can be sent from any replica 1 gets executed only when log record is committed in replicated log. O usually sent from leader, which knows which part of log it is committed. Eg! Fault tolerant key-value store :- o State: key -value storage state operations get () and put are first logged. : operations executed when the log record is in committed state < Even get () operations need to be processed via log 8 Part-B 6)b) Challenges in Maintaining Data consistency: 1) Data discrepancy occurs when the data in the target database deriates from the source database. The extent to which the data deviates depends on various factors, some of which may be included and others unintended #) Even using products that replicates data reliably there remain potential causes of data discrepancy If the goal of target databases is to be strictly consistent with the source database, then 19 will need to put processes and policy in place to ensure this outcome b) some of the potential causes Migration Errors: Different ponds of migration tools are employed to facilitate the crital load of the target database before replication 9) can begin. Difference in configuration for handling data by the migration tools and replication products can result is data discrepencies Lift and Shift workload to cloud: Since the world is moring towards cloud, the lift and shift of database workload from on-premises to cloud is the need of today's IT world. Difference in source and Target: Different including, locates - endianner or database sersions can cause subte discrepencies to happen during migration and replication configuration errors: Improper and unconfiguration of replication products can cause discrepencies. This type of discrepency doser't show ap a the replication logs, since from the replication products perspective if is forming as configured 10 user error: often target databases are treated to offload query processing from the source database. Requirements for managing Data consistency: b) High speed, low impact data comparisons #) support for heterogeneous database k) Capability for handling large datas. #). Minimally intrusive x) Data Security. 4) MYSQL enables restrictions to be placed on rease of previous passwords To establish passward-reuse policy globally, use the password history and password_reuse - internal System variables. 2). Database indexing Hash tables may also be used as disk-based data structures and database indices although B- trees are more popular in these applications, hash tables are commonly used to reduce network traffic 11 3) Advantages : 1. Data Retreivel 2. Editing Dis Advantages 1. Data Redundancy 2. Data inconsistency. 1) The mean time is 100000 2(120100). system 5). Map database, is used because it is designed efficiently to store and recall spactial information CAT-3 2127200801094 Thanigaikelann IT 18305 Database Management INT-B systeri 8 b The deadlock - prevention and deadlock. detection algrithms can be used in a distributed system, provided that modification are Made. FBI example, we can use the tree protocol by defining a global tree among the system data items. similarly, the tirestamp - ordering approach could be directly applied to a distributed environment Deadlock prevention May result in unnecessary waiting and rollburs furthersta, certain dealbock preventson technique May requires more site to be involved in the execution of a transaction than would otherwise be the case. If me allow deadlocks to occur and on deadlock detection, the Main problem in a distributed reply system is deciding how to maintain the wait for graphs. T, T2 T2 T4 T5 T3 T3 COMMON techniques for dealing with this issue require that each site keep a local wait for graph The node of the graph correspond to all the transactions (local as well as noulocar) that are Currently either holding or requesting any of the items local to that site. Example: depices a system consisting of two sites each maintaining its local wait - for graph Note the transactions T2 and T3 appear in both graphs, indicating that the transactions have requested items as both sites when a transaction Ti on site S, needs a resource in site S2, it sends a request Message to site S2. If the resource is held by transaction Tj, the system insert an edges T; T in the local wast- for graph of site S2 In the centralized deadlock detection approach the system constructs and maintains a global wastfor graph in a single site the deadlock-detection - coordinator since there is communication delay in the system, we must distinguish between two types of wait - for graphs. The real graph describes the real but unknown state of the system at any instance in time, as would be seen by an omnisciend observer. T1 T1 T2 T3 S1 S2 T1 T2 T3 coordinator The global wait for graph can be reconstruct ted or updated under the conditions. - whenever a new edge is inserted in or removed from one of the local wait for graphs periodically, when a number of changes have occurred in a local wait for graph. whenever the coordinator needs 10 invoke the cycle- detection algorithm False cycles exist in the global mont for graph As am illustration, consider a snapshor of the system represented by the local wait for graph suppose that T2 redease the resource that is holding in site S1, resulting in the delection of the edge T, T2 in S1. Transaction T2 then request a resource held by T3 at site S2, resulting in the - addition of the edges T2 T3 ins, If the insert T2 T3 message from S2 arrius before the remone T, T2 Message from S., then coordinator May discover the false cycle T, T2 Ts after the insert. A deadlock has indeed occured and a victim has been picked, while one of the transactions was aborted for reasons unrelated to the deadlock For example, suppose that site S, decides to about T2. At the same time, the coordinator has discovered a cycle and was picked T3 as a victim Both T2. and T3 are now rolled back, although only T2 needed f 0 be rolled back part- 6 b Executive overreven The requirement for high data availability and the need to access data or hear 24/7/365 without performance degradation and service interruption has created the need for having redundant distributed copes of the data However in today's complex It environment where data increases in light speed, maintaining data consistency across distributed copies of data is challenging and the possibility of data discripary is an unfortunate reality oracle gddengate veredata provides an easy - to - use get powerful solution for identifying out of synch data before it negatively impacts the business. Deployed together with the oracle Goldengate real-time - data replication product or separately, oracle goldengate vridada data consistency is maintained across databases ensures challenges in maintaining Data consistancy byfre we discuss the requirements for the solution that helps Manage data consestancy across database, we need to understand the COMMON causes of data discrepancies in an enterprese Data discrepancy occurs when the data in the target database desiates from the source database The extent to which the data deviates depends on various fallors, some of which May be intended and others instended some of the potential causes of data Discripancy are described in the following sections migration error Different kind of Migration tools are empty to faciliate the initial load of the starget databa before replication can begin Differences in configurate for handing data by the migration tools and replica products can result in data discrepancies For example. a migration tool May use"?" and the replication product May use Null" when the value of the column is known. lift & shift worload to cloud since the world is Moving towards cloud, the lift & shift of database workload from on premises to cloud is the need of todays IT world racle gddengate helps moving the work load, the data consistency across on - premises and cloud data Difference in source and Target Different including, locates, endianner or database versions can Cause rubte descriputions to happen during migration and replication instantiation cross world migration of replication can begin the target database will need to be instantiated with the correct schema and constraints Failure to do so will result in the same and target being out of sync. configuration Errors: Improper and untanded configuration of replication products can cause descriptions This type of discropality doesn't show up in the replicate lags since from the replication product perpective it is forming as configured. Replication latency with assynchranous replication there well be a short lag between changes to the service database and delivery to those chang to the target Failure to Meet the Maximum latency requirement however can potentially violate service level agreement levels or data compriance requirements, user errors :- often target databases are treated to offload Quary processing from the source database This enable rich operational reporting without impacting the application running on stone source database Requirements for managing Data consisting : high speed , low impact data comparisons support for heleroganoous databases capability for handling large data volumes flexible options for Managing data comparent nonimally intrusive & support for line databases with constantly changing date comparson of only changed data in continous replication. comparison of huge table through automailed and Manual partiering Data comparison reports for auditing pwg Data security Easy to use, understand Configure, deploy and diagness 7 a) Fault. tolerand servites using replicated state Machine Key requirement : Make a service fault tolerant E.g : lock Manager, They - value system state Machines are a powerful approach to creating such services A state Machine - Has a stored state, and receives input - Makes state transitions on each input and may output some results - Transition and output must be determinist A replicated state Machine is a Rstrave Machine that is replicated on Multiple nodes. - All replicas must get exactly the same inputs - Replicated log! state Machine processes only committed inputs - Even if some of the nodes fail, state and output can be obtained from other hodey Replicated state machine Replicated state Machine based on replicated doo Example commands assign values to variables client concersus module consensus consenses n 3 Module n 3 y 7 Module x 3 y 7 y # z Log 3 log Z 3 = 3 2 log x< y-4 ye- 7 xx-2 22-2 x yea Ye- plan 2 2 xc- Leader follower follower leader - declares log record corrutted after it replicated at a Majority of nodes, update of state Machine at each replica happens only after log record has been committed uses of replicated state Machine peplicated state Machines Can be used is implement wide variety of servites input can specify operations with parameters - But operation Must be deterministin - Result of operation can be sent from any replica crets executed only when log records is committed in replicated log usually sent from leader which Knows which part of log is committed Example: fault towart lock manager state: lock table operations: lock requests and lock reals output grant, or rollback requests on deadlock centralized implementation is made fault tolerant by simply running it on a replicated state machine. Fault dolerent Key - value store state They - value storage state operations. get() and pul() are first logged operations executed when the long round is in committed state note even gde operations need to be processed via by Google spanner uses replicated state Machine to implement They value store Data is partitioned and each partners is replicated across multiple nodes. Peplicas of a portition form a some going with one node as leader operations indiated at leader and replicated to other hoder part-A 3. Advantages of storing Multiple relations in a single file: complex structures can be implemented through the DBMS, thus increasing performance Disaduantages of storing Multiple relation in a single file Increases the size and complexity of the DBMS I For the two dirk mirrored care, me assume A disk and B disk In order to lose data; A and B need to be failed at the same time. If A is already failed and within 100,000 hours B disk will fail, then data will be lost. The other case is B is already failed and within 100,000 hours A will fael and then data will be lost. For the first case, A disk is failed for 100 hours every 100, 000 hours. so in order to Make B to fa it will need 100, 00012/100 hours Because the other Care, the time is reduced to 100,000 162 100) 3. Advantage pata retrieval: computer- based system provide enhanced data reterenal techniques to retrieve data stored in files in easy and efficient way. Editing It is a easy to edit any information stored in computers in form of files. specific application programs or editing software Can be used for this purpose. Disadvantage * Data redundancy It is possible that the information May be duplicated in different in files. This same Leads to data redundanly results memory mastage. pata inconsistenty Because of data redundar it is possible that data May not be in consistant star 5. Map database Management system are software programs designed to efficiently store and recall spatial information They are widely used in localization and navigation, especially in automotive applications They are playing an increasingly important role in the emerging areas of location based services, active safety function and advanced driver - assistance system common to there functions is the requireMent for Clus on - board Map database that contains information describing the road network 2. Database indexing, Hash tables May also be used as disk - based data structures and database indicas (such as in dbM) although B- trees more popular in these applications in murlt:- - node database system hash tables are commonly used sto destribute rours amongst nodes, reducing network traffic enobles restrictions to be placed on reuse of 4. be mysol placed on reuse of previous passwords. To establish history password. - reuse policy globally, use the password and password reuse internal system variables (AT-III Name: G. Navina Branch : IT - B Regno: 2127200801059 Subcode: IT18305 Subject Database system name Part - C 8b) The deadlock - prevention and deadlack-detection algorithm can be used in distrubed system, provided that modification are made. Deadlack prevention may result in unnecessary waiting and rollback If we allow deadlocks to accur and rely an deadlock detection the main problem in a disturbed system is deciding how to maintain wait-for-graph Common technique for dealing with this to issue require the each site keep a local wait far graph the nodes of the graph correspond to all the 2 transaction that are currently either holding or requesting any of the items local to that site T T 3 T2 ) 4 T5 T3 T3 Eg:- The above system consisting of 2 sites each maintaining its local wait - for gaph Note that transaction T2 and T3 appear in bath graphs, indicating that the transaction have requested X2 C requested items at both sites These local wait for graph are constructed in the usual manner for local transaction and datailems. when Transaction T; an site S, needs a resource in sites, it send a request message to site S2 If the resource is both held by transaction Tj. then system inserts an edge Ti Tj in the local wait for 3 graph site S2 . Each wait - for graph is acydic novertheless a deadlock exist in the system because the union of the local wait-fue graphs (centains a cycle In the centralized deadlock detection approach the system constructs and mountans a global Wait for graph un a single site, the deadlack detection coordinator. since there is communication delay in the system we must distinguish between the 2 types of wait for graph The global wait -far - graph can be reconstructed as updated under these conditions :- A whenever a new edge is inserted in or removed from are of the local wait for graph & Periodically when a number of changes have occured in a local wait for graph 4 whenever the loar dinator needs to invoke the cycle - detection algorithm when the caardinator invokes the deadlach detection algarithm, it searches its glob al graph If itfinds a cycle, it selects avictim do be rolled bach The locardinator must notify all the sites that a particular transaction has been selected as victim and sites, in turn roll back False cycles :- It exist in the glabal wait for graph. Suppose that T2 releases the resource that it is halching in site S, resulting in the deleticen of edge T, T2 ins, -7 Transaction 72 then requstes a resource held by T3 at the rts site S2 resulting in the additi an of edge T2 T3 in S2 If the insert T2 T3 message from S2 arrives before the remove T, T2 message froms, 5 the lacardinatar may discover the false cycle Tg T2 T3 after the insert Deadlock recovery may be initiated although no deadlock has occured T 1, T1 I2 3 T S2 2 3 S1 coordinator Part- - B 6 (b) challenges in maintaining Data consistency:- Data descrepancy accurs when the data in the target database deviates from the source database Same potential cause of data discrepancy:- Migration error: Different kinds of migration toots are employed to facilitate the initial lead of the target database before replication begins 6 Lift & shift workload to cloud be Difference in source and target ie Difference in source and target database configuration Instantiation error, before migration or replicati an configuration error. can begin the target database will need to be instantiated with correct schema and constaints, failure to do. so will lead to saurce and target being out ofsgue configuration error improp es and unintended configuration of replication products can cause dis crepancies Gaps in replication Replication latency user error, application error Requirements for managing data consistency High speed law impact data comparisons 7 a support far heterogeneaus database capability far handling large data volumes Minimal intrusive Suppar far love database with constantly changing dat a Flexible options fees managing data compariscens. Part-c 7(a) Fault - Tolerant services wing Replication state machines Key requirement td make a service fault tolerant eg:- lack manager, key value storage system state machines are a powerful approach to creating such service A state machines has a stared state, and receives inputs Makes state transitions on each input and may output some results 8 Transitions and output must be determinist A replicated state machine is a state machine that is replicated an multiple mades A All replicas must get exactly the same input Replicated lag! state machine processes anly committed inputs Even if same of the mades fail state and output can be obtained from other nades. Replicated state machine clisit ye? consenses x 3 module x3 y 7 x3 y7 log J7 23 23 Log 23 xt2 XL2 YEL yey xt2 t2 ye3 yty xt2 7 leader follower follower 9 Replicated state machine based on replicated bey Example command assign values to variables Use of Replicated state machines Impurs tax sy Replicated state machines can be used to implement wide variety of services . Input can specify aperations with parameter to operations must be deterministic Result of operation can be sent from any replica example :- Fault - talerant lack manager State : lack table operation: lack requests and lock releases output: grant, as ralback requests an deadlack centralized implementation is made fault tolerant by simply running it on a replicated state machine Fault tolerant key value store & state : key - value storage state 10 operation get 11 and put 11 are first logged Gaagle spanner uses replicated state machine to implement ky-valu stare Part - A 3] Advantages of staring multiple relation in singlefile complex structures can be implemented through the DBMS , thus increasing performance Dired Dis advantages :- A Increases the size and complexity of the DBMS 5] Map database management system are software programs designed to efficiently store andrecall spatial in formation. Used in localization and of automative localization especiall in automative applications 1] Mean time to failure of dist A is 1,00,000 Shows time to repair is 10 hours gives mean time to data loss of 500 X 106 hours or 57000 yars for a mirrared pairs of disks